{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib    import pyplot as plt\n",
    "from numpy.random  import default_rng\n",
    "from tqdm          import tqdm\n",
    "from time          import perf_counter \n",
    "from scipy.stats   import pearsonr, poisson, wishart, multivariate_normal, norm, vonmises, multivariate_t, laplace\n",
    "from scipy.special import gamma, factorial, gammaln\n",
    "from scipy.special import i0 as I0\n",
    "from dw_tools      import bivariate_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional joint probability distribution of $(E_1, E_2)$ given $E_3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acentric case\n",
    "Following https://en.wikipedia.org/wiki/Multivariate_normal_distribution#Conditional_distributions, \n",
    "\n",
    "$$\n",
    "P\\left(E_1,E_2 | E_3\\right) = P\\left(E_{1x},E_{2x},E_{1y},E_{2x}|E_{3x}, E_{3y}\\right)=N\\left(r E_3,C_{1,2|3}\\right)\n",
    "$$\n",
    "\n",
    "(note the rearrangement of rows), with conditional covariance matrix\n",
    "\n",
    "$$\n",
    "C_{1,2|3} = \\frac{1}{2}\n",
    "\\begin{bmatrix}\n",
    "1   -r^2 & r_x -r^2 & 0       & 0        \\\\\n",
    "r_x -r^2 & 1   -r^2 & 0       & 0        \\\\\n",
    "0        & 0        & 1  -r^2 & r_x -r^2 \\\\\n",
    "0        & 0        & r_x-r^2 & 1 -r^2  \n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "- $r$ and $r_x$ cannot adopt arbitrary combinations of values. Specifically, the conditional covariance matrix is only positive definite if $1+r_x \\geq 2r^2$. \n",
    "- $E_1$ and $E_2$ are conditionally independent (and uncorrelated) when $r_x = r^2$. In that case, $1+r_x = 1+r^2 \\geq 2r^2 $.\n",
    "- In our case, $r_x$ or ```rx``` is the correlation between components of the ON and OFF structure factors. $r$ or ```r``` is the correlation between ON or OFF structure factors and the reference data. The prior can be made irrelevant by setting $r=0$.\n",
    "- Setting both $r$ and $r_x$ to 0 reduces the prior to the product of Wilson distributions.\n",
    "- Previous analysis suggests $r \\sim 0.9$ and $r_x > 0.98$ as typical values. \n",
    "- As we saw previously, $r$ and $r_x$ are generally functions of resolution that can be well-described by forms $r=a e^{-bs^2}$. For an ON/OFF data set, one could estimate $a, b, a_x, b_x$ by maximum likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centric case\n",
    "Following https://en.wikipedia.org/wiki/Multivariate_normal_distribution#Conditional_distributions, \n",
    "\n",
    "$$\n",
    "P\\left(E_{1c},E_{2c} | E_{3c}\\right) = N\\left(r E_{3c},C_{1c|3c}\\right)\n",
    "$$\n",
    "\n",
    "with \n",
    "\n",
    "$$\n",
    "C_{1c|3c} = \n",
    "\\begin{bmatrix}\n",
    "1   -r^2 & r_x -r^2 \\\\\n",
    "r_x -r^2 & 1   -r^2         \n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then have that \n",
    "\n",
    "$$\n",
    "P\\left(|E_{1c}|,|E_{2c}| | |E_{3c}|\\right) = P\\left(E_{1c},E_{2c} | E_{3c}\\right) + \n",
    "                                             P\\left(-E_{1c},E_{2c} | E_{3c}\\right) +\n",
    "                                             P\\left(E_{1c},-E_{2c} | E_{3c}\\right) +\n",
    "                                             P\\left(-E_{1c},-E_{2c} | E_{3c}\\right)\n",
    "$$\n",
    "\n",
    "There should not be any need to further simplify this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "The bivariate Rice distribution and 2D folded normal are validated in **6_Bivariate_priors_tidy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "E1 = 1\n",
    "E2 = 2\n",
    "E3 = 2\n",
    "r  = 0.0\n",
    "rx = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3852087261928682e-11\n",
      "2.289987096433528e-22\n"
     ]
    }
   ],
   "source": [
    "print(bivariate_tools.FoldedNorm2D_wrapper(  E1=E1, E2=E2, rx=rx, E3=E3, r=r, Sigma=1.0)) # acentric\n",
    "print(bivariate_tools.Bivariate_Rice_wrapper(E1=E1, E2=E2, rx=rx, E3=E3, r=r, Sigma=1.0)) #  centric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 2)\n",
      "Elapsed time: 12.2 s\n",
      "Integrated probability density (acentric): 0.0\n",
      "Integrated probability density (acentric): 0.9934\n"
     ]
    }
   ],
   "source": [
    "nx, ny = (200,200)\n",
    "xy_max = 6\n",
    "xbase  = np.linspace(0.001, xy_max, nx)\n",
    "ybase  = np.linspace(0.001, xy_max, ny)\n",
    "xx,yy  = np.meshgrid(xbase,ybase)\n",
    "y_in   = np.transpose(np.array([xx.flatten(), yy.flatten()]))\n",
    "print(y_in.shape)\n",
    "\n",
    "t1_start = perf_counter()  \n",
    "result_ac = np.zeros((nx,ny))\n",
    "result_c  = np.zeros((nx,ny))\n",
    "for i in range(nx):\n",
    "    for j in range(ny):\n",
    "#         result_ac[i,j] = bivariate_tools.Bivariate_Rice_wrapper(xbase[i],ybase[j],rx,E3,r)\n",
    "        result_c[ i,j] = bivariate_tools.FoldedNorm2D_wrapper(    xbase[i],ybase[j],rx,E3,r)\n",
    "t1_end = perf_counter()  \n",
    "\n",
    "print(f\"Elapsed time: {t1_end-t1_start:.3} s\")\n",
    "print(f\"Integrated probability density (acentric): {np.sum(result_ac[:])*((xy_max/nx)*(xy_max/ny)):.4}\")\n",
    "print(f\"Integrated probability density (acentric): {np.sum(result_c[ :])*((xy_max/nx)*(xy_max/ny)):.4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On my laptop, it took 1.7 sec for 40,000 acentric calculations, and 13.3 sec for centric calculations. Neither functions is vectorized. There is, however, a vectorized version of the 2D folded normal in ```bivariate_tools.py```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.0156 s\n",
      "Integrated probability density (acentric): 0.9934\n"
     ]
    }
   ],
   "source": [
    "t1_start = perf_counter()  \n",
    "result_c = bivariate_tools.FoldedNorm2D_vect_wrapper(y_in[:,0].reshape(-1,1), y_in[:,1].reshape(-1,1),rx,E3,r)\n",
    "result_c = result_c.reshape(nx,ny)\n",
    "t1_end = perf_counter()  \n",
    "\n",
    "print(f\"Elapsed time: {t1_end-t1_start:.3} s\")\n",
    "print(f\"Integrated probability density (acentric): {np.sum(result_c[ :])*((xy_max/nx)*(xy_max/ny)):.4}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "831px",
    "left": "25px",
    "top": "110px",
    "width": "340px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
